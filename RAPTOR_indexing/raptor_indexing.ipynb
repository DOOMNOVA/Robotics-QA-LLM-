{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the textbook embeddings and instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings_to_pickle(file_path):\n",
    "    with open(file_path,'rb') as f:\n",
    "        embedding_with_metadata = pickle.load(f)\n",
    "    return embedding_with_metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
    "\n",
    "\n",
    "\n",
    "#helper function to embed text chunks with metadata\n",
    "def embed_text_chunks(textbook_chunk_metadata,model):\n",
    "    for chunk in textbook_chunk_metadata:\n",
    "        text_chunk = chunk['text_chunk']\n",
    "        embedding = model.encode(text_chunk)\n",
    "        chunk['embedding'] = embedding\n",
    "    return textbook_chunk_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_textbook_embed = load_embeddings_to_pickle('/Users/haridevaraj/Documents/Projects/steps_ai/Content_extraction_and_chunking_embed/combined_textbook_embedding_metadata.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# textbook1_embed = load_embeddings_to_pickle('/Users/haridevaraj/Documents/Projects/steps_ai/Content_extraction_and_chunking_embed/textbook1_embedding_metadata.pkl')\n",
    "# textbook2_embed =load_embeddings_to_pickle('/Users/haridevaraj/Documents/Projects/steps_ai/Content_extraction_and_chunking_embed/textbook2_embedding_metadata.pkl')\n",
    "# textbook3_embed =load_embeddings_to_pickle('/Users/haridevaraj/Documents/Projects/steps_ai/Content_extraction_and_chunking_embed/textbook3_embedding_metadata.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAPTOR indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from typing import Optional\n",
    "import umap\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmm_cluster_embeddings_prob_threshold(textbook_embeddings,random_state=42):\n",
    "    num_clusters = get_bayesian_optimal_num_clusters(textbook_embeddings)\n",
    "    \n",
    "    gmm = GaussianMixture(n_components=num_clusters,covariance_type='full',random_state=random_state)\n",
    "    gmm.fit(textbook_embeddings)\n",
    "    clusters = gmm.predict_proba(textbook_embeddings)\n",
    "    return clusters, gmm\n",
    "\n",
    "#get the optimal number using the Bayesian Information criteria with a GMM\n",
    "def get_bayesian_optimal_num_clusters(textbook_embeddings,max_clusters=30,random_state=42):\n",
    "    max_clusters = min(max_clusters,len(textbook_embeddings))\n",
    "    n_clusters = np.arange(1,max_clusters)\n",
    "    \n",
    "    bayesian_info_criteria=[]\n",
    "    \n",
    "    for num in n_clusters:\n",
    "        gmm = GaussianMixture(n_components=num,random_state=random_state)\n",
    "        gmm.fit(textbook_embeddings)\n",
    "        bayesian_info_criteria.append(gmm.bic())\n",
    "    optim_clusters = n_clusters[np.argmin(bayesian_info_criteria)]\n",
    "    \n",
    "    return optim_clusters\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.array([chunk['embedding']]for chunk in combined_textbook_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(<generator object <genexpr> at 0x12a0c5b10>, dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reducing the cluster using UMAP dimensionality reduction in global and local dimensionality\n",
    "def umap_red_global_cluster_embed(textbook_embeddings,dim,n_neighbours=None,metric='cosine'):\n",
    "    if n_neighbhours is None:\n",
    "        n_neighbhours = int((len(textbook_embeddings)-1)**0.5)\n",
    "    global_embed= umap.UMAP(n_neighbours=n_neighbhours,n_components=dim,metric=metric).fit_transform(texbook_embeddings)\n",
    "    return global_embed\n",
    "\n",
    "\n",
    "def umap_local_cluster_embed(textbook_embeddings,dim,num_neighbhours=10,metric='cosine'):\n",
    "    local_embed = umap.UMAP(n_neighbours=num_neighbhours,n_components=dim,metric=metric).fit_transform(textbook_embeddings)\n",
    "    return local_embed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "steps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
